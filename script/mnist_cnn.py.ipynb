{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "# \u4f7f\u7528\u3059\u308b\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\n",
      "import numpy as np\n",
      "import matplotlib.pylab as plt\n",
      "from matplotlib import cm\n",
      "from sklearn.datasets import fetch_mldata\n",
      "import time\n",
      "\n",
      "import os\n",
      "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
      "import tensorflow as tf\n",
      "\n",
      "# define network\n",
      " \n",
      "# placeholder\uff08input image x.shape\uff0coutput y\uff09\n",
      "x_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
      "y_ = tf.placeholder(tf.float32, shape=(None, 10))\n",
      "\n",
      "# conv1\n",
      "conv1_features = 20 # conv1 dimention20\n",
      "max_pool_size1 = 2 # conv1\n",
      "\n",
      "conv1_w = tf.Variable(tf.truncated_normal([5, 5, 1, conv1_features], stddev=0.1), dtype=tf.float32) # \u7573\u307f\u8fbc\u307f\u5c641\u306e\u91cd\u307f\u2190\u66f4\u65b0\u3057\u3066\u3044\u304f\n",
      "conv1_b = tf.Variable(tf.constant(0.1, shape=[conv1_features]), dtype=tf.float32) # \u7573\u307f\u8fbc\u307f\u5c641\u306e\u30d0\u30a4\u30a2\u30b9\n",
      "\n",
      "conv1_c2 = tf.nn.conv2d(x_, conv1_w, strides=[1, 1, 1, 1], padding=\"SAME\") # \u7573\u307f\u8fbc\u307f\u5c641-\u7573\u307f\u8fbc\u307f\n",
      "conv1_relu = tf.nn.relu(conv1_c2+conv1_b) # \u7573\u307f\u8fbc\u307f\u5c641-ReLU\n",
      "conv1_mp = tf.nn.max_pool(conv1_relu, ksize=[1, max_pool_size1, max_pool_size1, 1], strides=[1, max_pool_size1, max_pool_size1, 1], padding=\"SAME\") # \u7573\u307f\u8fbc\u307f\u5c641-\u30de\u30c3\u30af\u30b9\u30d7\u30fc\u30ea\u30f3\u30b0\n",
      "\n",
      "\n",
      "# \u7573\u307f\u8fbc\u307f\u5c642\n",
      "conv2_features = 50 # \u7573\u307f\u8fbc\u307f\u5c642\u306e\u51fa\u529b\u6b21\u5143\u6570\n",
      "max_pool_size2 = 2 # \u7573\u307f\u8fbc\u307f\u5c642\u306e\u30de\u30c3\u30af\u30b9\u30d7\u30fc\u30ea\u30f3\u30b0\u306e\u30b5\u30a4\u30ba\n",
      "conv2_w = tf.Variable(tf.truncated_normal([5, 5, conv1_features, conv2_features], stddev=0.1), dtype=tf.float32) # \u7573\u307f\u8fbc\u307f\u5c642\u306e\u91cd\u307f\n",
      "conv2_b = tf.Variable(tf.constant(0.1, shape=[conv2_features]), dtype=tf.float32) # \u7573\u307f\u8fbc\u307f\u5c642\u306e\u30d0\u30a4\u30a2\u30b9\n",
      "conv2_c2 = tf.nn.conv2d(conv1_mp, conv2_w, strides=[1, 1, 1, 1], padding=\"SAME\") # \u7573\u307f\u8fbc\u307f\u5c642-\u7573\u307f\u8fbc\u307f\n",
      "conv2_relu = tf.nn.relu(conv2_c2+conv2_b) # \u7573\u307f\u8fbc\u307f\u5c642-ReLU\n",
      "conv2_mp = tf.nn.max_pool(conv2_relu, ksize=[1, max_pool_size2, max_pool_size2, 1], strides=[1, max_pool_size2, max_pool_size2, 1], padding=\"SAME\") # \u7573\u307f\u8fbc\u307f\u5c642-\u30de\u30c3\u30af\u30b9\u30d7\u30fc\u30ea\u30f3\u30b0\n",
      "\n",
      "# \u5168\u7d50\u5408\u5c641\n",
      "print 'mixed1.shape:',x_.get_shape()[1]#28[2]28\n",
      "result_w = x_.get_shape()[1] // (max_pool_size1*max_pool_size2)\n",
      "result_h = x_.get_shape()[2] // (max_pool_size1*max_pool_size2)\n",
      "\n",
      "fc_input_size = result_w * result_h * conv2_features # \u7573\u307f\u8fbc\u3093\u3060\u7d50\u679c\u3001\u5168\u7d50\u5408\u5c64\u306b\u5165\u529b\u3059\u308b\u6b21\u5143\u6570\n",
      "fc_features = 500 # \u5168\u7d50\u5408\u5c64\u306e\u51fa\u529b\u6b21\u5143\u6570\uff08\u96a0\u308c\u5c64\u306e\u6b21\u5143\u6570\uff09\n",
      "s = conv2_mp.get_shape().as_list() # [None, result_w, result_h, conv2_features]\n",
      "conv_result = tf.reshape(conv2_mp, [-1, s[1]*s[2]*s[3]]) # \u7573\u307f\u8fbc\u307f\u306e\u7d50\u679c\u30921*N\u5c64\u306b\u5909\u63db\n",
      "fc1_w = tf.Variable(tf.truncated_normal([fc_input_size.value, fc_features], stddev=0.1), dtype=tf.float32) # \u91cd\u307f\n",
      "fc1_b = tf.Variable(tf.constant(0.1, shape=[fc_features]), dtype=tf.float32) # \u30d0\u30a4\u30a2\u30b9\n",
      "fc1 = tf.nn.relu(tf.matmul(conv_result, fc1_w)+fc1_b) # \u5168\u7d50\u5408\u5c641\n",
      "\n",
      "\n",
      "# \u5168\u7d50\u5408\u5c642\n",
      "fc2_w = tf.Variable(tf.truncated_normal([fc_features, fc_features], stddev=0.1), dtype=tf.float32) # \u91cd\u307f\n",
      "fc2_b = tf.Variable(tf.constant(0.1, shape=[fc_features]), dtype=tf.float32) # \u30d0\u30a4\u30a2\u30b9\n",
      "fc2 = tf.nn.relu(tf.matmul(fc1, fc2_w)+fc2_b) # \u5168\u7d50\u5408\u5c642\n",
      "\n",
      "\n",
      "# \u5168\u7d50\u5408\u5c643\n",
      "fc3_w = tf.Variable(tf.truncated_normal([fc_features, 10], stddev=0.1), dtype=tf.float32) # \u91cd\u307f\n",
      "fc3_b = tf.Variable(tf.constant(0.1, shape=[10]), dtype=tf.float32) # \u30d0\u30a4\u30a2\u30b9\n",
      "#\u6700\u5f8c\u306e\u6700\u5f8c\u306b\u6c42\u307e\u308b\u51fa\u529b\n",
      "y = tf.matmul(fc2, fc3_w)+fc3_b\n",
      "\n",
      "\n",
      "# \u30af\u30ed\u30b9\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u8aa4\u5dee\u3068\u306f\u8aa4\u5dee\u95a2\u6570\u3084\uff01\u671f\u5f85\u5024\uff08\u5b9f\u969b\u306e\u5024\uff08\u60c5\u5831\u91cf\uff09\u3068\u78ba\u7387\uff09\n",
      "#E = tf.reduce_mean((function(x,e,a,b,c,d)-y)**2,0)\n",
      "#labels _y\u304c\u78ba\u7387\u3067y\u304c\u60c5\u5831\u91cf\uff1f\uff1d\u671f\u5f85\u5024\n",
      "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
      "\n",
      "\n",
      "# \u52fe\u914d\u6cd5\u3000\u6700\u6025\u964d\u4e0b\u6cd5\u3067\u5b66\u7fd2\u3055\u305b\u3066\u3044\u308b\n",
      "#train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
      "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
      "\n",
      "\n",
      "# \u6b63\u89e3\u7387\u306e\u8a08\u7b97\n",
      "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
      " \n",
      "# \u5b66\u7fd2\n",
      " \n",
      "EPOCH_NUM = 1    #default 5\n",
      "BATCH_SIZE = 1000    #default 1000\n",
      " \n",
      "# \u6559\u5e2b\u30c7\u30fc\u30bf\n",
      "mnist = fetch_mldata('MNIST original', data_home='.')\n",
      "mnist.data = mnist.data.astype(np.float32) # image data 784*70000 [[0-255, 0-255, ...], [0-255, 0-255, ...], ... ]\n",
      "mnist.data /= 255 # 0-1\u306b\u6b63\u898f\u5316\u3059\u308b\n",
      "mnist.target = mnist.target.astype(np.int32) # \u30e9\u30d9\u30eb\u30c7\u30fc\u30bf70000\n",
      "#print 'ready mnist data'\n",
      "\n",
      "# \u6559\u5e2b\u30c7\u30fc\u30bf\u3092\u5909\u63db\n",
      "N = 60000\n",
      "train_x, test_x = np.split(mnist.data,   [N]) # \u6559\u5e2b\u30c7\u30fc\u30bf\n",
      "train_y, test_y = np.split(mnist.target, [N]) # \u30c6\u30b9\u30c8\u7528\u306e\u30c7\u30fc\u30bf\n",
      "train_x = train_x.reshape((len(train_x), 28, 28, 1)) # (N, height, width, channel)\n",
      "test_x = test_x.reshape((len(test_x), 28, 28, 1))\n",
      "\n",
      "# \u30e9\u30d9\u30eb\u306fone-hot\u30d9\u30af\u30c8\u30eb\u306b\u5909\u63db\u3059\u308b\n",
      "train_y = np.eye(np.max(train_y)+1)[train_y]\n",
      "test_y = np.eye(np.max(test_y)+1)[test_y]\n",
      "\n",
      "saver = tf.train.Saver()\n",
      "# \u5b66\u7fd2\n",
      "#print(\"Train\")\n",
      "saver = tf.train.Saver()\n",
      "with tf.Session() as sess:\n",
      "    sess.run(tf.global_variables_initializer())\n",
      "    #sess.run(tf.initialize_all_variables())\n",
      "    for epoch in range(EPOCH_NUM):\n",
      "        perm = np.random.permutation(N)\n",
      "        total_loss = 0\n",
      "        for i in range(0, N, BATCH_SIZE):\n",
      "            batch_x = train_x[perm[i:i+BATCH_SIZE]]\n",
      "            batch_y = train_y[perm[i:i+BATCH_SIZE]]\n",
      "            total_loss += cross_entropy.eval(feed_dict={x_: batch_x, y_: batch_y})\n",
      "            train_step.run(feed_dict={x_: batch_x, y_: batch_y})\n",
      "            #print 'i:{},batch_x:{},batch_y:{}'.format(i,batch_x.shape,batch_y.shape)\n",
      "            #print 'result_w,h:',result_w,result_h #7 7\n",
      "            #print 'cross:',train_step\n",
      "            #print 'y:',y\n",
      "        #print 'y:',y\n",
      "        test_accuracy = accuracy.eval(feed_dict={x_: test_x, y_: test_y})\n",
      "        if (epoch+1) % 1 == 0:\n",
      "            print 'epoch:\\t{}\\ttotal loss:\\t{}\\tvaridation accuracy:\\t{}'.format(epoch+1, total_loss, test_accuracy)\n",
      "    saver.save(sess,'/home/roboworks/deepdream/ckpt/model.ckpt')\n",
      "    # \u4e88\u6e2c\n",
      "    print '\\nPredict'\n",
      "    idx = np.random.choice(70000-N, 10)\n",
      "    for i in idx:\n",
      "        pre = np.argmax(y.eval(feed_dict={x_: [test_x[i]]}))\n",
      "        plt.figure(figsize=(1,1))\n",
      "        plt.imshow(test_x[i].reshape(28,28), cmap=cm.gray_r)\n",
      "        plt.show()\n",
      "        print 'correct_data:',[[test_x[i]]]\n",
      "        print 'y:',y.eval(feed_dict={x_: [test_x[i]]})\n",
      "        print 'predict:', pre, '\\n'\n",
      "        #print '=&gt;', pre, '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%whos |grep intf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable         Type    Data/Info\n",
        "----------------------------------\n",
        "BATCH_SIZE       int     1000\n",
        "EPOCH_NUM        int     1\n",
        "N                int     60000\n",
        "conv1_features   int     20\n",
        "conv2_features   int     50\n",
        "epoch            int     0\n",
        "fc_features      int     500\n",
        "max_pool_size1   int     2\n",
        "max_pool_size2   int     2\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%whos |grep Tensor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable             Type      Data/Info\n",
        "----------------------------------------\n",
        "accuracy             Tensor    Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
        "conv1_c2             Tensor    Tensor(\"Conv2D:0\", shape=<...>, 28, 20), dtype=float32)\n",
        "conv1_mp             Tensor    Tensor(\"MaxPool:0\", shape<...>, 14, 20), dtype=float32)\n",
        "conv1_relu           Tensor    Tensor(\"Relu:0\", shape=(?<...>, 28, 20), dtype=float32)\n",
        "conv2_c2             Tensor    Tensor(\"Conv2D_1:0\", shap<...>, 14, 50), dtype=float32)\n",
        "conv2_mp             Tensor    Tensor(\"MaxPool_1:0\", sha<...>7, 7, 50), dtype=float32)\n",
        "conv2_relu           Tensor    Tensor(\"Relu_1:0\", shape=<...>, 14, 50), dtype=float32)\n",
        "conv_result          Tensor    Tensor(\"Reshape:0\", shape<...>(?, 2450), dtype=float32)\n",
        "correct_prediction   Tensor    Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
        "cross_entropy        Tensor    Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
        "fc1                  Tensor    Tensor(\"Relu_2:0\", shape=(?, 500), dtype=float32)\n",
        "fc2                  Tensor    Tensor(\"Relu_3:0\", shape=(?, 500), dtype=float32)\n",
        "x_                   Tensor    Tensor(\"Placeholder:0\", s<...>8, 28, 1), dtype=float32)\n",
        "y                    Tensor    Tensor(\"add_4:0\", shape=(?, 10), dtype=float32)\n",
        "y_                   Tensor    Tensor(\"Placeholder_1:0\",<...>e=(?, 10), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%whos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Variable             Type         Data/Info\n",
        "-------------------------------------------\n",
        "BATCH_SIZE           int          1000\n",
        "EPOCH_NUM            int          1\n",
        "N                    int          60000\n",
        "accuracy             Tensor       Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
        "batch_x              ndarray      1000x28x28x1: 784000 elems, type `float32`, 3136000 bytes (2 Mb)\n",
        "batch_y              ndarray      1000x10: 10000 elems, type `float64`, 80000 bytes\n",
        "cm                   module       <module 'matplotlib.cm' f<...>on2.7/matplotlib/cm.pyc'>\n",
        "conv1_b              Variable     <tf.Variable 'Variable_1:<...>=(20,) dtype=float32_ref>\n",
        "conv1_c2             Tensor       Tensor(\"Conv2D:0\", shape=<...>, 28, 20), dtype=float32)\n",
        "conv1_features       int          20\n",
        "conv1_mp             Tensor       Tensor(\"MaxPool:0\", shape<...>, 14, 20), dtype=float32)\n",
        "conv1_relu           Tensor       Tensor(\"Relu:0\", shape=(?<...>, 28, 20), dtype=float32)\n",
        "conv1_w              Variable     <tf.Variable 'Variable:0'<...>1, 20) dtype=float32_ref>\n",
        "conv2_b              Variable     <tf.Variable 'Variable_3:<...>=(50,) dtype=float32_ref>\n",
        "conv2_c2             Tensor       Tensor(\"Conv2D_1:0\", shap<...>, 14, 50), dtype=float32)\n",
        "conv2_features       int          50\n",
        "conv2_mp             Tensor       Tensor(\"MaxPool_1:0\", sha<...>7, 7, 50), dtype=float32)\n",
        "conv2_relu           Tensor       Tensor(\"Relu_1:0\", shape=<...>, 14, 50), dtype=float32)\n",
        "conv2_w              Variable     <tf.Variable 'Variable_2:<...>0, 50) dtype=float32_ref>\n",
        "conv_result          Tensor       Tensor(\"Reshape:0\", shape<...>(?, 2450), dtype=float32)\n",
        "correct_prediction   Tensor       Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
        "cross_entropy        Tensor       Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
        "epoch                int          0\n",
        "fc1                  Tensor       Tensor(\"Relu_2:0\", shape=(?, 500), dtype=float32)\n",
        "fc1_b                Variable     <tf.Variable 'Variable_5:<...>(500,) dtype=float32_ref>\n",
        "fc1_w                Variable     <tf.Variable 'Variable_4:<...>, 500) dtype=float32_ref>\n",
        "fc2                  Tensor       Tensor(\"Relu_3:0\", shape=(?, 500), dtype=float32)\n",
        "fc2_b                Variable     <tf.Variable 'Variable_7:<...>(500,) dtype=float32_ref>\n",
        "fc2_w                Variable     <tf.Variable 'Variable_6:<...>, 500) dtype=float32_ref>\n",
        "fc3_b                Variable     <tf.Variable 'Variable_9:<...>=(10,) dtype=float32_ref>\n",
        "fc3_w                Variable     <tf.Variable 'Variable_8:<...>0, 10) dtype=float32_ref>\n",
        "fc_features          int          500\n",
        "fc_input_size        Dimension    2450\n",
        "fetch_mldata         function     <function fetch_mldata at 0x7effdeb09050>\n",
        "i                    int64        2581\n",
        "idx                  ndarray      10: 10 elems, type `int64`, 80 bytes\n",
        "max_pool_size1       int          2\n",
        "max_pool_size2       int          2\n",
        "mnist                Bunch        {'data': array([[0., 0., <...>, 9, 9, 9], dtype=int32)}\n",
        "np                   module       <module 'numpy' from '/us<...>.egg/numpy/__init__.pyc'>\n",
        "os                   module       <module 'os' from '/usr/lib/python2.7/os.pyc'>\n",
        "perm                 ndarray      60000: 60000 elems, type `int64`, 480000 bytes (468 kb)\n",
        "plt                  module       <module 'matplotlib.pylab<...>.7/matplotlib/pylab.pyc'>\n",
        "pre                  int64        1\n",
        "result_h             Dimension    7\n",
        "result_w             Dimension    7\n",
        "s                    list         n=4\n",
        "saver                Saver        <tensorflow.python.traini<...>object at 0x7effd258ce90>\n",
        "sess                 Session      <tensorflow.python.client<...>object at 0x7effd26a8c90>\n",
        "test_accuracy        float32      0.819\n",
        "test_x               ndarray      10000x28x28x1: 7840000 elems, type `float32`, 31360000 bytes (29 Mb)\n",
        "test_y               ndarray      10000x10: 100000 elems, type `float64`, 800000 bytes (781 kb)\n",
        "tf                   module       <module 'tensorflow' from<...>tensorflow/__init__.pyc'>\n",
        "time                 module       <module 'time' (built-in)>\n",
        "total_loss           float64      79.99515467882156\n",
        "train_step           Operation    name: \"GradientDescent\"\\n<...>9/ApplyGradientDescent\"\\n\n",
        "train_x              ndarray      60000x28x28x1: 47040000 elems, type `float32`, 188160000 bytes (179 Mb)\n",
        "train_y              ndarray      60000x10: 600000 elems, type `float64`, 4800000 bytes (4 Mb)\n",
        "x_                   Tensor       Tensor(\"Placeholder:0\", s<...>8, 28, 1), dtype=float32)\n",
        "y                    Tensor       Tensor(\"add_4:0\", shape=(?, 10), dtype=float32)\n",
        "y_                   Tensor       Tensor(\"Placeholder_1:0\",<...>e=(?, 10), dtype=float32)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}